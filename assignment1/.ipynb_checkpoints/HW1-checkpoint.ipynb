{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################################################\n",
    "## ASSIGNMENT 1 CODE SKELETON\n",
    "## RELEASED: 2/6/2019\n",
    "## DUE: 2/15/2019\n",
    "## DESCRIPTION: In this assignment, you will explore the\n",
    "## text classification problem of identifying complex words.\n",
    "## We have provided the following skeleton for your code,\n",
    "## with several helper functions, and all the required\n",
    "## functions you need to write.\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "training_file = \"data/complex_words_training.txt\"\n",
    "development_file = \"data/complex_words_development.txt\"\n",
    "test_file = \"data/complex_words_test_unlabeled.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Input: y_pred, a list of length n with the predicted labels,\n",
    "## y_true, a list of length n with the true labels\n",
    "\n",
    "## Calculates the precision of the predicted labels\n",
    "def get_precision(y_pred, y_true):\n",
    "    ## YOUR CODE HERE...\n",
    "    TP, FP = 0, 0\n",
    "    \n",
    "    for index in range(len(y_pred)):\n",
    "        if y_pred[index] == 1:\n",
    "            if y_true[index] == 1:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "\n",
    "    precision = TP / (TP + FP)\n",
    "\n",
    "    return precision\n",
    "    \n",
    "## Calculates the recall of the predicted labels\n",
    "def get_recall(y_pred, y_true):\n",
    "    ## YOUR CODE HERE...\n",
    "    TP, FN = 0, 0\n",
    "\n",
    "    for index in range(len(y_pred)):\n",
    "        if y_pred[index] == y_true[index] == 1:\n",
    "            TP += 1\n",
    "        elif y_pred[index] == 0 != y_true[index]:\n",
    "            FN += 1\n",
    "    \n",
    "    recall = TP / (TP + FN)\n",
    "\n",
    "    return recall\n",
    "\n",
    "## Calculates the f-score of the predicted labels\n",
    "def get_fscore(y_pred, y_true):\n",
    "    ## YOUR CODE HERE...\n",
    "    P = get_precision(y_pred, y_true)\n",
    "    R = get_recall(y_pred, y_true)\n",
    "\n",
    "    fscore = 2 * P * R / (P + R)\n",
    "\n",
    "    return fscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Complex Word Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Loads in the words and labels of one of the datasets\n",
    "def load_file(data_file):\n",
    "    words = []\n",
    "    labels = []   \n",
    "    with open(data_file, 'rt', encoding=\"utf8\") as f:\n",
    "        i = 0\n",
    "        for line in f:\n",
    "            if i > 0:\n",
    "                line_split = line[:-1].split(\"\\t\")\n",
    "                words.append(line_split[0].lower())\n",
    "                labels.append(int(line_split[1]))\n",
    "            i += 1\n",
    "    return words, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1: A very simple baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------2.1 Test---------------------------------------\n",
      "training performance: {'precision': 0.43133333333333335, 'recall': 1.0, 'fscore': 0.6027014438751747}\n",
      "development performance: {'precision': 0.418, 'recall': 1.0, 'fscore': 0.5895627644569816}\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## Makes feature matrix for all complex\n",
    "def all_complex_feature(words):\n",
    "    return [1 for x in range(len(words))]\n",
    "\n",
    "## Labels every word complex\n",
    "def all_complex(data_file):\n",
    "    ## YOUR CODE HERE...\n",
    "    words, y_true = load_file(data_file)\n",
    "\n",
    "    y_pred = all_complex_feature(words)\n",
    "\n",
    "    precision = get_precision(y_pred, y_true)\n",
    "    recall = get_recall(y_pred, y_true)\n",
    "    fscore = get_fscore(y_pred, y_true)\n",
    "    \n",
    "    performance = {'precision': precision, 'recall': recall, 'fscore': fscore}\n",
    "    return performance\n",
    "\n",
    "# ------------------2.1 Test---------------------------------------\n",
    "print('------------------2.1 Test---------------------------------------')\n",
    "\n",
    "performance_training = all_complex(training_file)\n",
    "print('training performance:', performance_training)\n",
    "\n",
    "performance_development = all_complex(development_file)\n",
    "print('development performance:', performance_development)\n",
    "\n",
    "print('-----------------------------------------------------------------')\n",
    "# -----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2: Word length thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------2.2 Test---------------------------------------\n",
      "the best threshould for training data (using F1-score): 7\n",
      "training performance: {'precision': 0.5985877240630092, 'recall': 0.8516228748068007, 'fscore': 0.7030303030303029}\n",
      "development performance: {'precision': 0.6053511705685619, 'recall': 0.8660287081339713, 'fscore': 0.7125984251968505}\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## Makes feature matrix for word_length_threshold\n",
    "def length_threshold_feature(words, threshold):\n",
    "    y_pred = []\n",
    "    for word in words:\n",
    "        if len(word) < threshold:\n",
    "            y_pred.append(0)\n",
    "        else:\n",
    "            y_pred.append(1)\n",
    "    return y_pred\n",
    "\n",
    "## Finds the best length threshold by f-score, and uses this threshold to\n",
    "## classify the training and development set\n",
    "def word_length_threshold(training_file, development_file):\n",
    "    ## YOUR CODE HERE\n",
    "    training_words, training_y_true = load_file(training_file)\n",
    "    development_words, development_y_true = load_file(development_file)\n",
    "\n",
    "    best_threshold = 0\n",
    "    max_fscore = 0\n",
    "    best_training_performance = None\n",
    "    for threshold in range(1, 20):\n",
    "        # training_performance = [tprecision, trecall, tfscore]\n",
    "        training_y_pred = length_threshold_feature(training_words, threshold)\n",
    "            \n",
    "        training_performance = {'precision': get_precision(training_y_pred, training_y_true),\n",
    "                                'recall': get_recall(training_y_pred, training_y_true),\n",
    "                                'fscore': get_fscore(training_y_pred, training_y_true)}\n",
    "        if max_fscore < training_performance['fscore']:\n",
    "            max_fscore = training_performance['fscore']\n",
    "            best_training_performance = training_performance\n",
    "            best_threshold = threshold\n",
    "\n",
    "    print('the best threshould for training data (using F1-score):', best_threshold)\n",
    "    \n",
    "    # development_performance = [dprecision, drecall, dfscore]\n",
    "    development_y_pred = length_threshold_feature(development_words, best_threshold)\n",
    "    development_performance = {'precision': get_precision(development_y_pred, development_y_true),\n",
    "                            'recall': get_recall(development_y_pred, development_y_true),\n",
    "                            'fscore': get_fscore(development_y_pred, development_y_true)}\n",
    "    \n",
    "    return best_training_performance, development_performance\n",
    "\n",
    "# ------------------2.2 Test---------------------------------------\n",
    "print('------------------2.2 Test---------------------------------------')\n",
    "\n",
    "performance_training, performance_development = word_length_threshold(training_file, development_file)\n",
    "print('training performance:', performance_training)\n",
    "print('development performance:', performance_development)\n",
    "\n",
    "print('-----------------------------------------------------------------')\n",
    "# -----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3: Word frequency thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Loads Google NGram counts\n",
    "def load_ngram_counts(ngram_counts_file): \n",
    "   counts = defaultdict(int) \n",
    "   with gzip.open(ngram_counts_file, 'rt', encoding='UTF-8') as f: \n",
    "       for line in f:\n",
    "           token, count = line.strip().split('\\t') \n",
    "           if token[0].islower(): \n",
    "               counts[token] = int(count) \n",
    "   return counts\n",
    "\n",
    "ngram_counts_file = \"ngram_counts.txt.gz\"\n",
    "counts = load_ngram_counts(ngram_counts_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------2.3 Test---------------------------------------\n",
      "max_fscore_approx = 0.602841835546238 in threshold scope ( 1 - 47376829650 )\n",
      "max_fscore_approx = 0.602841835546238 in threshold scope ( 1 - 47376829650 )\n",
      "max_fscore_approx = 0.6358897989575577 in threshold scope ( 1 - 200000001 )\n",
      "max_fscore_approx = 0.6685516808042729 in threshold scope ( 1 - 30000001 )\n",
      "max_fscore_approx = 0.6685516808042729 in threshold scope ( 19000001 - 21000001 )\n",
      "max_fscore_approx = 0.6693954659949621 in threshold scope ( 19600001 - 20000001 )\n",
      "max_fscore_approx = 0.6693980460132367 in threshold scope ( 19720001 - 19740001 )\n",
      "max_fscore_approx = 0.6693980460132367 in threshold scope ( 19727001 - 19733001 )\n",
      "max_fscore_approx = 0.6693980460132367 in threshold scope ( 19727701 - 19732101 )\n",
      "max_fscore_approx = 0.6693980460132367 in threshold scope ( 19727781 - 19732011 )\n",
      "max_fscore_approx = 0.6693980460132367 in threshold scope ( 19727786 - 19732011 )\n",
      "---------------------------\n",
      "best threshold for training data: 19732010 , best fscore: 0.6693980460132367\n",
      "---------------------------\n",
      "max_fscore_approx = 0.5895627644569816 in threshold scope ( 1 - 47376829650 )\n",
      "max_fscore_approx = 0.5899788285109385 in threshold scope ( 1 - 2000000001 )\n",
      "max_fscore_approx = 0.6175807663410969 in threshold scope ( 1 - 200000001 )\n",
      "max_fscore_approx = 0.6704653371320038 in threshold scope ( 1 - 30000001 )\n",
      "max_fscore_approx = 0.6759720837487537 in threshold scope ( 13000001 - 16000001 )\n",
      "max_fscore_approx = 0.6779999999999999 in threshold scope ( 14100001 - 15000001 )\n",
      "max_fscore_approx = 0.6779999999999999 in threshold scope ( 14870001 - 14930001 )\n",
      "max_fscore_approx = 0.6779999999999999 in threshold scope ( 14873001 - 14921001 )\n",
      "max_fscore_approx = 0.6779999999999999 in threshold scope ( 14873701 - 14920201 )\n",
      "max_fscore_approx = 0.6779999999999999 in threshold scope ( 14873731 - 14920111 )\n",
      "max_fscore_approx = 0.6779999999999999 in threshold scope ( 14873738 - 14920111 )\n",
      "---------------------------\n",
      "best threshold for development data: 14920110 , best fscore: 0.6779999999999999\n",
      "---------------------------\n",
      "training performance: {'precision': 0.5651942522618414, 'recall': 0.8207109737248841, 'fscore': 0.6693980460132367}\n",
      "development performance: {'precision': 0.5824742268041238, 'recall': 0.8110047846889952, 'fscore': 0.6779999999999999}\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Finds the best frequency threshold by f-score, and uses this threshold to\n",
    "## classify the training and development set\n",
    "\n",
    "## Make feature matrix for word_frequency_threshold\n",
    "def frequency_threshold_feature(words, threshold, counts):\n",
    "    y_pred = []\n",
    "    for word in words:\n",
    "        if counts[word] < threshold:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "    return y_pred\n",
    "\n",
    "def word_frequency_threshold(training_file, development_file, counts):\n",
    "    ## YOUR CODE HERE\n",
    "    training_words, training_y_true = load_file(training_file)\n",
    "    development_words, development_y_true = load_file(development_file)\n",
    "    \n",
    "    def find_best_threshold(words, y_true):\n",
    "        min_freq = np.min(list(counts.values()))\n",
    "        max_freq = np.max(list(counts.values()))\n",
    "        \n",
    "        max_fscore = 0\n",
    "        best_threshold = 0\n",
    "        \n",
    "        scope = 10000000000\n",
    "        lower, upper = min_freq + 1, max_freq\n",
    "        while(scope > 0):\n",
    "            current_lower, current_upper = lower, upper\n",
    "            flag = False\n",
    "            for threshold in range(current_lower, current_upper, scope):\n",
    "                y_pred = frequency_threshold_feature(words, threshold, counts)\n",
    "                fscore = get_fscore(y_pred, y_true)\n",
    "                if fscore >= max_fscore:\n",
    "                    max_fscore = fscore\n",
    "                    best_threshold = threshold\n",
    "                    if flag == False:\n",
    "                        lower = max(min_freq + 1, threshold - scope)\n",
    "                        flag = True\n",
    "                    upper = min(threshold + scope, max_freq - 1)\n",
    "            \n",
    "            scope = int(scope / 10)\n",
    "            \n",
    "            print('max_fscore_approx =', max_fscore, 'in threshold scope (', lower, '-', upper, ')')\n",
    "            \n",
    "        return best_threshold, fscore\n",
    "    \n",
    "    training_best_threshold, training_fscore = find_best_threshold(training_words, training_y_true)\n",
    "    \n",
    "    print('---------------------------')\n",
    "    print(\"best threshold for training data:\", training_best_threshold, \", best fscore:\", training_fscore)\n",
    "    print('---------------------------')\n",
    "    \n",
    "    training_y_pred = frequency_threshold_feature(training_words, training_best_threshold, counts)\n",
    "    # training_performance = [tprecision, trecall, tfscore]\n",
    "    training_performance = {'precision': get_precision(training_y_pred, training_y_true),\n",
    "                                'recall': get_recall(training_y_pred, training_y_true),\n",
    "                                'fscore': get_fscore(training_y_pred, training_y_true)}\n",
    "    \n",
    "    development_best_threshold, development_fscore = find_best_threshold(development_words, development_y_true)\n",
    "    \n",
    "    print('---------------------------')\n",
    "    print(\"best threshold for development data:\", development_best_threshold, \", best fscore:\", development_fscore)\n",
    "    print('---------------------------')\n",
    "    \n",
    "    development_y_pred = frequency_threshold_feature(development_words, development_best_threshold, counts)\n",
    "    # development_performance = [dprecision, drecall, dfscore]\n",
    "    development_performance = {'precision': get_precision(development_y_pred, development_y_true),\n",
    "                                'recall': get_recall(development_y_pred, development_y_true),\n",
    "                                'fscore': get_fscore(development_y_pred, development_y_true)}\n",
    "    \n",
    "    return training_performance, development_performance\n",
    "\n",
    "\n",
    "# ------------------2.3 Test---------------------------------------\n",
    "print('------------------2.3 Test---------------------------------------')\n",
    "\n",
    "training_performance, development_performance = word_frequency_threshold(training_file, development_file, counts)\n",
    "print('training performance:', training_performance)\n",
    "print('development performance:', development_performance)\n",
    "\n",
    "print('-----------------------------------------------------------------')\n",
    "# -----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_length_and_frequency(words, counts, mean=None, std=None):\n",
    "        length_frequency = []\n",
    "        for word in words:\n",
    "            length_frequency.append([len(word), counts[word]])\n",
    "        \n",
    "        length_frequency = np.array(length_frequency)\n",
    "        \n",
    "        if mean is None:\n",
    "            mean = np.mean(length_frequency, axis=0)\n",
    "            std = np.std(length_frequency, axis=0)\n",
    "        normalized_length_frequency = (length_frequency - mean) / std\n",
    "        \n",
    "        return normalized_length_frequency, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------2.4 Test---------------------------------------\n",
      "training performance: {'precision': 0.4918351477449456, 'recall': 0.9775888717156105, 'fscore': 0.6544231764097258}\n",
      "development performance: {'precision': 0.4700352526439483, 'recall': 0.9569377990430622, 'fscore': 0.6304176516942475}\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## Trains a Naive Bayes classifier using length and frequency features\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def naive_bayes(training_file, development_file, counts):\n",
    "    ## YOUR CODE HERE\n",
    "    training_words, training_y_true = load_file(training_file)\n",
    "    development_words, development_y_true = load_file(development_file)\n",
    "    \n",
    "    X_train, training_mean, training_std = get_length_and_frequency(training_words, counts)\n",
    "    Y_train = np.array(training_y_true)\n",
    "    \n",
    "    NB_classifier = GaussianNB()\n",
    "    NB_classifier.fit(X_train, Y_train)\n",
    "    \n",
    "    X_development, _, _ = get_length_and_frequency(development_words, counts, training_mean, training_std)\n",
    "    Y_development = np.array(development_y_true)\n",
    "    development_y_pred = NB_classifier.predict(X_development)\n",
    "    \n",
    "    # development_performance = (dprecision, drecall, dfscore)\n",
    "    development_performance = {'precision': get_precision(development_y_pred, development_y_true),\n",
    "                                'recall': get_recall(development_y_pred, development_y_true),\n",
    "                                'fscore': get_fscore(development_y_pred, development_y_true)}\n",
    "    return development_performance\n",
    "\n",
    "# ------------------2.4 Test---------------------------------------\n",
    "print('------------------2.4 Test---------------------------------------')\n",
    "\n",
    "training_performance = naive_bayes(training_file, training_file, counts)\n",
    "development_performance = naive_bayes(training_file, development_file, counts)\n",
    "print('training performance:', training_performance)\n",
    "print('development performance:', development_performance)\n",
    "\n",
    "print('-----------------------------------------------------------------')\n",
    "# -----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------2.5 Test---------------------------------------\n",
      "training performance: {'precision': 0.7206751054852321, 'recall': 0.6599690880989181, 'fscore': 0.6889874949576441}\n",
      "development performance: {'precision': 0.7229219143576826, 'recall': 0.6866028708133971, 'fscore': 0.7042944785276073}\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## Trains a Naive Bayes classifier using length and frequency features\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def logistic_regression(training_file, development_file, counts):\n",
    "    ## YOUR CODE HERE\n",
    "    training_words, training_y_true = load_file(training_file)\n",
    "    development_words, development_y_true = load_file(development_file)\n",
    "    \n",
    "    X_train, training_mean, training_std = get_length_and_frequency(training_words, counts)\n",
    "    Y_train = np.array(training_y_true)\n",
    "    \n",
    "    LR_classifier = LogisticRegression()\n",
    "    LR_classifier.fit(X_train, Y_train)\n",
    "    \n",
    "    X_development, _, _ = get_length_and_frequency(development_words, counts, training_mean, training_std)\n",
    "    Y_development = np.array(development_y_true)\n",
    "    development_y_pred = LR_classifier.predict(X_development)\n",
    "    \n",
    "    # development_performance = (dprecision, drecall, dfscore)\n",
    "    development_performance = {'precision': get_precision(development_y_pred, development_y_true),\n",
    "                                'recall': get_recall(development_y_pred, development_y_true),\n",
    "                                'fscore': get_fscore(development_y_pred, development_y_true)}\n",
    "    return development_performance\n",
    "\n",
    "# ------------------2.5 Test---------------------------------------\n",
    "print('------------------2.5 Test---------------------------------------')\n",
    "\n",
    "training_performance = logistic_regression(training_file, training_file, counts)\n",
    "development_performance = logistic_regression(training_file, development_file, counts)\n",
    "print('training performance:', training_performance)\n",
    "print('development performance:', development_performance)\n",
    "\n",
    "print('-----------------------------------------------------------------')\n",
    "# -----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7: Build your own classifier\n",
    "\n",
    "Trains a classifier of your choosing, predicts labels for the test dataset\n",
    "\n",
    "and writes the predicted labels to the text file 'test_labels.txt',\n",
    "\n",
    "with ONE LABEL PER LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.        ,  1.        ,  1.        , 10.        ,  1.        ],\n",
       "        [ 1.        , -1.        ,  3.        ,  5.        ,  0.18552972]]),\n",
       " array([5.5000000e+00, 1.2079797e+07]),\n",
       " array([1.5000000e+00, 1.0133909e+07]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import syllables\n",
    "from nltk.corpus import wordnet \n",
    "\n",
    "def get_features(words, counts, normalize_mean=None, normalize_std=None):\n",
    "    length_frequency, normalize_mean, normalize_std = get_length_and_frequency(words, counts, normalize_mean, normalize_std)\n",
    "    syllable_count = []\n",
    "    synonym_count= []\n",
    "    frequency_ratio = []\n",
    "    \n",
    "    for word in words:\n",
    "        syllable_count.append([syllables.count_syllables(word)])\n",
    "        \n",
    "        synonym = []\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for orginal in syn.lemmas():\n",
    "                synonym.append(orginal.name())\n",
    "        synonym = set(synonym)\n",
    "        \n",
    "        synonym_count.append([len(synonym)])\n",
    "        \n",
    "        if len(synonym) > 0:\n",
    "            synonym_frequency = [counts[x] for x in synonym]\n",
    "            frequency_ratio.append([counts[word] / np.max(synonym_frequency)])\n",
    "        else:\n",
    "            frequency_ratio.append([0])\n",
    "    \n",
    "    features = np.concatenate((np.array(length_frequency), np.array(syllable_count), \n",
    "                               np.array(synonym_count), np.array(frequency_ratio)), axis=1)\n",
    "    features = np.nan_to_num(features, 0)\n",
    "    \n",
    "    return features, normalize_mean, normalize_std\n",
    "\n",
    "get_features(['cool', 'awesome'], counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance(y_pred, y_true):\n",
    "    performance = {'precision': get_precision(y_pred, y_true),\n",
    "                'recall': get_recall(y_pred, y_true),\n",
    "                'fscore': get_fscore(y_pred, y_true)}\n",
    "    return performance\n",
    "\n",
    "training_file = \"data/complex_words_training.txt\"\n",
    "development_file = \"data/complex_words_development.txt\"\n",
    "test_file = \"data/complex_words_test_unlabeled.txt\"\n",
    "\n",
    "training_words, training_labels = load_file(training_file)\n",
    "development_words, development_labels = load_file(development_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\ljsPC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "e:\\Users\\ljsPC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in long_scalars\n",
      "e:\\Users\\ljsPC\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]]\n",
      "[1 1 1 ... 1 1 1]\n",
      "training perofrmance: {'precision': 0.43133333333333335, 'recall': 1.0, 'fscore': 0.6027014438751747}\n",
      "[[0. 0. 0. 0. 0.]]\n",
      "[1 1 1 ... 1 1 1]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-f73cad0c64da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'training perofrmance:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_performance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_y_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mdevelopment_y_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevelopment_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'development performance:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_performance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevelopment_y_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevelopment_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-132-091ab533647d>\u001b[0m in \u001b[0;36mget_performance\u001b[1;34m(y_pred, y_true)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_performance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     performance = {'precision': get_precision(y_pred, y_true),\n\u001b[0m\u001b[0;32m      3\u001b[0m                 \u001b[1;34m'recall'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mget_recall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                 'fscore': get_fscore(y_pred, y_true)}\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mperformance\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-7c52bf52c634>\u001b[0m in \u001b[0;36mget_precision\u001b[1;34m(y_pred, y_true)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m                 \u001b[0mTP\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def SVM(training_words, training_labels, predict_words, counts):\n",
    "    \n",
    "    \n",
    "    training_features, mean, std = get_features(training_words, counts)\n",
    "    \n",
    "    SVM_classifier = SVC(kernel='linear')\n",
    "    SVM_classifier.fit(training_features, training_labels)\n",
    "    \n",
    "    print(SVM_classifier.coef_ )\n",
    "    predict_features, _, _ = get_features(training_words, counts, mean, std)\n",
    "    y_pred = SVM_classifier.predict(predict_features)\n",
    "    print(y_pred)\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "training_y_pred = SVM(training_words, training_labels, training_words, counts)\n",
    "print('training perofrmance:', get_performance(training_y_pred, training_labels))\n",
    "development_y_pred = SVM(training_words, training_labels, development_words, counts)\n",
    "print('development performance:', get_performance(development_y_pred, development_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    training_file = \"data/complex_words_training.txt\"\n",
    "    development_file = \"data/complex_words_development.txt\"\n",
    "    test_file = \"data/complex_words_test_unlabeled.txt\"\n",
    "\n",
    "    train_data = load_file(training_file)\n",
    "    \n",
    "    ngram_counts_file = \"ngram_counts.txt.gz\"\n",
    "    counts = load_ngram_counts(ngram_counts_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
